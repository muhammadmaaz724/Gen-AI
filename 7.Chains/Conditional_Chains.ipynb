{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc29119f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint,ChatHuggingFace\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableBranch, RunnableLambda\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel,Field\n",
    "from typing import Literal\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id='meta-llama/Llama-3.3-70B-Instruct',\n",
    "    task='text-generation'\n",
    ")\n",
    "\n",
    "model = ChatHuggingFace(llm=llm)\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "234a3c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feedback(BaseModel):\n",
    "    sentiment: Literal['positive','negative'] = Field(\"Give the Sentiment of the feedback\")\n",
    "    \n",
    "parser2 = PydanticOutputParser(pydantic_object=Feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0f746ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1=PromptTemplate(\n",
    "    template='Classify the sentiment of the following feedback text into postive or negative \\n {feedback} \\n {format_ins}',\n",
    "    input_variables=['feedback'],\n",
    "    partial_variables={'format_ins':parser2.get_format_instructions()}\n",
    ")\n",
    "\n",
    "classifier_chain = prompt1 | model | parser2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7481ea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2=PromptTemplate(\n",
    "    template=\"Write an appropiate response to this positive Feedback \\n {feedback}\",\n",
    "    input_variables=[\"feedback\"]\n",
    ")\n",
    "\n",
    "prompt3=PromptTemplate(\n",
    "    template=\"Write an appropiate response to this negative Feedback \\n {feedback}\",\n",
    "    input_variables=[\"feedback\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc4c5bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_chain = RunnableBranch(\n",
    "    (lambda x:x.sentiment=='positive', prompt2 | model | parser),\n",
    "    (lambda x:x.sentiment=='negative', prompt3 | model | parser),\n",
    "    RunnableLambda(lambda x: \"could not found the sentiment\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "964155b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = classifier_chain | branch_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "84c988e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Thank you so much for your kind words! We're thrilled to hear that you've had a positive experience. Your feedback is greatly appreciated and we're glad we could meet your expectations. We'll keep working hard to provide the best possible service. Thank you again for your support!\"\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({'feedback': 'This is the best smartphone'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fc246752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    +-------------+      \n",
      "    | PromptInput |      \n",
      "    +-------------+      \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "   +----------------+    \n",
      "   | PromptTemplate |    \n",
      "   +----------------+    \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "  +-----------------+    \n",
      "  | ChatHuggingFace |    \n",
      "  +-----------------+    \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "+----------------------+ \n",
      "| PydanticOutputParser | \n",
      "+----------------------+ \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "       +--------+        \n",
      "       | Branch |        \n",
      "       +--------+        \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "    +--------------+     \n",
      "    | BranchOutput |     \n",
      "    +--------------+     \n"
     ]
    }
   ],
   "source": [
    "chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0bbbba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
