{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc29119f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint,ChatHuggingFace\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableBranch,RunnableLambda,RunnablePassthrough,RunnableParallel\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel,Field\n",
    "from typing import Literal\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id='meta-llama/Llama-3.3-70B-Instruct',\n",
    "    task='text-generation'\n",
    ")\n",
    "\n",
    "model = ChatHuggingFace(llm=llm)\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "234a3c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feedback(BaseModel):\n",
    "    sentiment: Literal['positive','negative'] = Field(\"Give the Sentiment of the feedback\")\n",
    "    \n",
    "parser2 = PydanticOutputParser(pydantic_object=Feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0f746ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1=PromptTemplate(\n",
    "    template='Classify the sentiment of the following feedback text into postive or negative \\n {feedback} \\n {format_ins}',\n",
    "    input_variables=['feedback'],\n",
    "    partial_variables={'format_ins':parser2.get_format_instructions()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7481ea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2=PromptTemplate(\n",
    "    template=\"Write an appropiate response to this positive Feedback \\n {feedback}\",\n",
    "    input_variables=[\"feedback\"]\n",
    ")\n",
    "\n",
    "prompt3=PromptTemplate(\n",
    "    template=\"Write an appropiate response to this negative Feedback \\n {feedback}\",\n",
    "    input_variables=[\"feedback\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc4c5bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = RunnableParallel({\n",
    "    'sentiment' : prompt1 | model | parser2,\n",
    "    'feedback' : RunnablePassthrough()\n",
    "})\n",
    "\n",
    "branch_chain = RunnableBranch(\n",
    "    (lambda x: x[\"sentiment\"].sentiment == \"positive\", prompt2 | model | parser),\n",
    "    (lambda x: x[\"sentiment\"].sentiment == \"negative\", prompt3 | model | parser),\n",
    "    RunnableLambda(lambda x: \"Could not determine sentiment.\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "964155b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = combined | branch_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84c988e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a potential response to the positive feedback:\n",
      "\n",
      "\"Thank you so much for your kind words! We're thrilled to hear that you're enjoying your smartphone and that it's meeting your expectations. We're constantly working to improve and innovate, and feedback like yours makes it all worth it. If you have any other questions or need any assistance, don't hesitate to reach out. Thanks again for choosing our product!\"\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({'feedback': 'This is the best smartphone'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc246752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        +-----------------------------------+      \n",
      "        | Parallel<sentiment,feedback>Input |      \n",
      "        +-----------------------------------+      \n",
      "                  ***            ***               \n",
      "                **                  ***            \n",
      "              **                       **          \n",
      "   +----------------+                    **        \n",
      "   | PromptTemplate |                     *        \n",
      "   +----------------+                     *        \n",
      "            *                             *        \n",
      "            *                             *        \n",
      "            *                             *        \n",
      "  +-----------------+                     *        \n",
      "  | ChatHuggingFace |                     *        \n",
      "  +-----------------+                     *        \n",
      "            *                             *        \n",
      "            *                             *        \n",
      "            *                             *        \n",
      "+----------------------+          +-------------+  \n",
      "| PydanticOutputParser |          | Passthrough |  \n",
      "+----------------------+          +-------------+  \n",
      "                  ***            ***               \n",
      "                     **        **                  \n",
      "                       **    **                    \n",
      "        +------------------------------------+     \n",
      "        | Parallel<sentiment,feedback>Output |     \n",
      "        +------------------------------------+     \n",
      "                           *                       \n",
      "                           *                       \n",
      "                           *                       \n",
      "                      +--------+                   \n",
      "                      | Branch |                   \n",
      "                      +--------+                   \n",
      "                           *                       \n",
      "                           *                       \n",
      "                           *                       \n",
      "                   +--------------+                \n",
      "                   | BranchOutput |                \n",
      "                   +--------------+                \n"
     ]
    }
   ],
   "source": [
    "chain.get_graph().print_ascii()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
