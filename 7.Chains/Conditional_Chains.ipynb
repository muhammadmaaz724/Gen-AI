{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc29119f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint,ChatHuggingFace\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableBranch, RunnableLambda\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel,Field\n",
    "from typing import Literal\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id='meta-llama/Llama-3.3-70B-Instruct',\n",
    "    task='text-generation'\n",
    ")\n",
    "\n",
    "model = ChatHuggingFace(llm=llm)\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "234a3c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feedback(BaseModel):\n",
    "    sentiment: Literal['positive','negative'] = Field(\"Give the Sentiment of the feedback\")\n",
    "    \n",
    "parser2 = PydanticOutputParser(pydantic_object=Feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0f746ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1=PromptTemplate(\n",
    "    template='Classify the sentiment of the following feedback text into postive or negative \\n {feedback} \\n {format_ins}',\n",
    "    input_variables=['feedback'],\n",
    "    partial_variables={'format_ins':parser2.get_format_instructions()}\n",
    ")\n",
    "\n",
    "classifier_chain = prompt1 | model | parser2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7481ea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2=PromptTemplate(\n",
    "    template=\"Write an appropiate response to this positive Feedback \\n {feedback}\",\n",
    "    input_variables=[\"feedback\"]\n",
    ")\n",
    "\n",
    "prompt3=PromptTemplate(\n",
    "    template=\"Write an appropiate response to this negative Feedback \\n {feedback}\",\n",
    "    input_variables=[\"feedback\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc4c5bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_chain = RunnableBranch(\n",
    "    (lambda x:x.sentiment=='positive', prompt2 | model | parser),\n",
    "    (lambda x:x.sentiment=='negative', prompt3 | model | parser),\n",
    "    RunnableLambda(lambda x: \"could not found the sentiment\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "964155b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = classifier_chain | branch_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84c988e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a potential response to negative feedback:\n",
      "\n",
      "\"Thank you for taking the time to share your concerns with us. We apologize that our [product/service] did not meet your expectations. We take all feedback seriously and would like to make things right. Can you please provide more details about your experience so we can better understand what went wrong? We'll do our best to address the issue and prevent it from happening again in the future. Your satisfaction is our top priority, and we appreciate your feedback in helping us improve.\"\n",
      "\n",
      "This response:\n",
      "\n",
      "* Acknowledges the customer's negative experience\n",
      "* Apologizes for the issue\n",
      "* Shows appreciation for the feedback\n",
      "* Requests more information to understand the issue\n",
      "* Expresses a commitment to making things right and improving the product/service\n",
      "\n",
      "Feel free to modify it to fit your specific needs and tone!\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({'feedback': 'This is the worst smart phone'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc246752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    +-------------+      \n",
      "    | PromptInput |      \n",
      "    +-------------+      \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "   +----------------+    \n",
      "   | PromptTemplate |    \n",
      "   +----------------+    \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "  +-----------------+    \n",
      "  | ChatHuggingFace |    \n",
      "  +-----------------+    \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "+----------------------+ \n",
      "| PydanticOutputParser | \n",
      "+----------------------+ \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "       +--------+        \n",
      "       | Branch |        \n",
      "       +--------+        \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "    +--------------+     \n",
      "    | BranchOutput |     \n",
      "    +--------------+     \n"
     ]
    }
   ],
   "source": [
    "chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0bbbba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
