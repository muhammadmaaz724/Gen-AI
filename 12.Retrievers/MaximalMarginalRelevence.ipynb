{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80ff9ae6",
   "metadata": {},
   "source": [
    "# MMR \n",
    "**when you use simple retreiver it can retrieve 2 docs which are talking about the same thing.**\n",
    "\n",
    "**when you MMR it helps to not pick the docs which are similar to each other or talking about the same thing.**\n",
    "\n",
    "**it depends on \"lambda_mult\" value it ranges between 0 and 1.**\n",
    "\n",
    "**If the value is 1 it acts like the simple retriever but when kept 0 it shows very diversity so it should be kept in between**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d93de2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "os.environ['HF_HOME'] = 'D:/NLP/huggingface_cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d50c75d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3363318",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "# Rewritten documents to better illustrate MMR and diversity in retrieval\n",
    "docs = [\n",
    "    Document(page_content=\"LangChain allows developers to build applications powered by large language models.\"),\n",
    "    Document(page_content=\"LangChain makes it easier to chain together LLMs with different tools and data sources.\"),\n",
    "    Document(page_content=\"Chroma is a vector store that helps in storing and retrieving document embeddings.\"),\n",
    "    Document(page_content=\"Embeddings are numerical vectors that capture the semantic meaning of text.\"),\n",
    "    Document(page_content=\"MMR is used in retrieval to return diverse yet relevant documents, avoiding redundancy.\"),\n",
    "    Document(page_content=\"LangChain integrates with multiple vector databases like Chroma, FAISS, and Pinecone.\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "657a92d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1eeb873f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectore_store = FAISS.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "78c4ee4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectore_store.as_retriever(\n",
    "    search_type = 'mmr',\n",
    "    search_kwargs = {'k':3,'lambda_mult':0.5}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ab3878d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'what is langchain?'\n",
    "\n",
    "res = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "49ccaf7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain allows developers to build applications powered by large language models.\n",
      "LangChain integrates with multiple vector databases like Chroma, FAISS, and Pinecone.\n",
      "LangChain makes it easier to chain together LLMs with different tools and data sources.\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(res)):\n",
    "    print(res[i].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4f8ae742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 LangChain allows developers to build applications powered by large language models.\n",
      "2 LangChain integrates with multiple vector databases like Chroma, FAISS, and Pinecone.\n",
      "3 LangChain makes it easier to chain together LLMs with different tools and data sources.\n"
     ]
    }
   ],
   "source": [
    "for i,doc in enumerate(res):\n",
    "    print(str(i+1)+\" \"+doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239b47f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
